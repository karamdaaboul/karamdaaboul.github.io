---
layout: post
title: "Seminar Overview"
date: 2024-06-01
categories: Seminar
excerpt: "A brief summary of the seminar focusing on key discussions and findings..."
---

## Overview
This page provides summaries of various seminar works I have observed and contributed to during my PhD program, categorized by key topics in machine learning. Each summary is followed by a link to the full document for those interested in more detailed information.

## Categories
- [Meta Reinforcement Learning](#meta-reinforcement-learning)
- [Representation Learning](#representation-learning)
- [Offline Reinforcement Learning](#offline-reinforcement-learning)

## Seminar Topics

### Meta Reinforcement Learning
<div id="meta-reinforcement-learning"></div>

#### Seminar: Model-Based Meta-Reinforcement Learning for Robust Decision Making
**Summary**: This seminar explores the combination of model-based reinforcement learning (MBRL) with meta-reinforcement learning (MRL) to address the challenges of adapting to new tasks with minimal data. It focuses on a dynamic, real-time learning framework that allows robotic systems to swiftly adjust to changes. [Read the full document](https://github.com/safebotics/safebotics.github.io/blob/master/assets/Model_Based_Meta_Reinforcement_Learning.pdf){:target="_blank"}

### Representation Learning
<div id="representation-learning"></div>

#### Seminar: Enhancing the Robustness of Learning Directly from the Pixel
**Summary**: This seminar tackles challenges in pixel-based RL, such as sample inefficiency and limited generalization, with strategies like contrastive learning to improve robustness and efficiency. [Read the full document](https://github.com/safebotics/safebotics.github.io/blob/master/assets/Enhancing_the_Robustness_of_Learning_Directly_from_the_Pixel__Seminar_Pascal_.pdf){:target="_blank"}

### Offline Reinforcement Learning
<div id="offline-reinforcement-learning"></div>

#### Seminar: Title and Overview
**Summary**: Description of the third seminar which relates to offline reinforcement learning. It might focus on strategies for training RL systems using previously stored data without ongoing interaction with the environment. [Read the full document](#)

