---
layout: post
title: "Seminar Overview"
date: 2024-06-01
categories: Seminar
excerpt: "A brief summary of the seminar focusing on key discussions and findings..."
---

## Overview
This page provides summaries of various seminar works I have observed and contributed to during my PhD program, categorized by key topics in machine learning. Each summary is followed by a link to the full document for those interested in more detailed information.

## Categories
- [Meta Reinforcement Learning](#meta-reinforcement-learning)
- [Representation Learning](#representation-learning)
- [Offline Reinforcement Learning](#offline-reinforcement-learning)
- [Model-based Reinforcement Learning](#model-based-reinforcement-learning)


## Seminar Topics

### Meta Reinforcement Learning
<div id="meta-reinforcement-learning"></div>

#### Seminar: Model-Based Meta-Reinforcement Learning for Robust Decision Making (2022)
**Summary**: This seminar explores the combination of model-based reinforcement learning (MBRL) with meta-reinforcement learning (MRL) to address the challenges of adapting to new tasks with minimal data. It focuses on a dynamic, real-time learning framework that allows robotic systems to swiftly adjust to changes. [Read the full document](https://<github.com/safebotics/safebotics.github.io/blob/master/assets/seminar_pdf/Model_Based_Meta_Reinforcement_Learning___Joel_Semianr.pdf){:target="_blank"}

#### Seminar: Exploring Meta-Learning Techniques in Reinforcement Learning (2021)
**Summary**: This seminar paper outlines the meta-reinforcement learning objective and several current algorithmic approaches. It discusses the concept of learning to quickly adapt model parameters based on prior experiences. [Read the full document](https://github.com/safebotics/safebotics.github.io/blob/master/assets/seminar_pdf/Exploring_Meta_Learning_Techniques_in_Reinforcement_Learnin__KD_.pdf){:target="_blank"}

### Representation Learning
<div id="representation-learning"></div>

#### Seminar: Enhancing the Robustness of Learning Directly from the Pixel (2023)
**Summary**: This seminar tackles challenges in pixel-based RL, such as sample inefficiency and limited generalization, with strategies like contrastive learning to improve robustness and efficiency. [Read the full document](https://github.com/safebotics/safebotics.github.io/blob/master/assets/seminar_pdf/Enhancing_the_Robustness_of_Learning_Directly_from_the_Pixel__Seminar_Pascal_.pdf){:target="_blank"}

#### Seminar: Generative Adversarial Networks for Data Augmentation (2023)
**Summary**: This paper discusses the application of Generative Adversarial Networks (GANs) to data augmentation. It explores various GAN architectures and techniques to stabilize their training, aiming to enhance the volume and diversity of data available for training neural networks, thus improving the performance in tasks with limited data availability. [Read the full document](https://github.com/safebotics/safebotics.github.io/blob/master/assets/seminar_pdf/Generative_Adversarial_Networks_for_Data_Augmentation.pdf){:target="_blank"}


### Offline Reinforcement Learning
<div id="offline-reinforcement-learning"></div>

#### Seminar: Offline Reinforcement Learning: Challenges and Solutions (2021)
**Summary**: This seminar paper explores Offline Reinforcement Learning (RL) and its use of large datasets to make decisions without continuous environment interaction. It reviews methods like Policy Constraint, Value-Regularization, Model-Based, and Uncertainty-Based approaches to tackle distributional shift. Benchmarks such as D4RL and RL Unplugged are discussed for evaluating these methods. The paper highlights current limitations and future directions for applying Offline RL to complex real-world tasks. [Read the full document](https://github.com/safebotics/safebotics.github.io/blob/master/assets/seminar_pdf/Seminararbeit_Offline_Reinforcement_Learning_eng_.pdf){:target="_blank"}

### Model-based Reinforcement Learning
<div id="model-based-reinforcement-learning"></div>

#### Seminar: Uncertainty and Prediction in Model-based Reinforcement Learning (2020)
**Summary**: This seminar explores different methods to capture model uncertainty in model-based reinforcement learning (MBRL). It discusses the advantages and disadvantages of Gaussian processes, Bayesian neural networks, and other approaches, focusing on their scalability and performance in complex tasks. [Read the full document](https://github.com/safebotics/safebotics.github.io/blob/master/assets/seminar_pdf/Uncertainty_and_Prediction_in_Model_based_Reinforcement_Learning.pdf){:target="_blank"}
